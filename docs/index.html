<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>Generative AI Inventory</title>
    <style>
        body {
            font-family: Vollkorn, Ubuntu, Optima, Segoe, Segoe UI, Candara, Calibri, Arial, sans-serif;
        }

        .group {
            display: inline-block;
            border: 1px solid lightgrey;
            border-radius: 6px;
            margin: 18px 18px 18px 18px;
            padding: 10px;
            background-color: #f8f8f8;
            width: 220px;
            vertical-align: top;
            box-shadow: rgba(0, 0, 0, 0.1) 0px 4px 12px;
            font-size: 110%;
        }

        a {
            text-decoration: none;
            color: black;
        }

        .icon {
            width: 140px;
            height: 140px;
            object-fit: cover;
            border-radius: 4px;
            margin-top: 26px;
            margin-bottom: 20px;
            filter: grayscale(100%);
        }

        body {
            margin: 40px;
            text-align: center;
        }

        ::placeholder {
            color: lightgrey;
            opacity: 1;
        }

        :-ms-input-placeholder {
            color: lightgrey;
        }

        ::-ms-input-placeholder {
            color: lightgrey;
        }

        .advice-as-title {
            font-size: 18px;
            font-weight: bold;
            margin-bottom: 14px;
            color: blue;
        }

        .ingredients {
            font-size: 14px;
            margin-bottom: 10px;
            border-left: 2px solid lightgrey;
            padding-left: 6px;
        }

        .ingredient {
            margin-bottom: 8px;
            font-size: 110%;
        }

        .guest {
            font-size: 12px;
            margin-bottom: 6px;
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
            padding: 5px 1px 5px;
            color: black;
        }

        .tab {
            overflow: hidden;
            border: 1px solid #ccc;
            background-color: #f1f1f1;
        }

        .tab button {
            background-color: inherit;
            float: left;
            border: none;
            outline: none;
            cursor: pointer;
            padding: 14px 16px;
            transition: 0.3s;
            font-size: 17px;
        }

        .tab button:hover {
            background-color: #ddd;
        }

        .tab button.active {
            background-color: #ccc;
        }

        .tabcontent {
            display: none;
            padding: 0;
            border: 1px solid #ccc;
            border-top: none;
        }
    </style>
    <link rel="stylesheet" target="_blank" href="https://fonts.googleapis.com/css?family=Ubuntu">
    <link rel="stylesheet" target="_blank" href="https://fonts.googleapis.com/css?family=Lato">
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-129891352-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());
        gtag('config', 'UA-129891352-1');
    </script>
    <script>
        function openTab(evt, cityName) {
            var i, tabcontent, tablinks;
            tabcontent = document.getElementsByClassName("tabcontent");
            for (i = 0; i < tabcontent.length; i++) {
                tabcontent[i].style.display = "none";
            }
            tablinks = document.getElementsByClassName("tablinks");
            for (i = 0; i < tablinks.length; i++) {
                tablinks[i].className = tablinks[i].className.replace(" active", "");
            }
            document.getElementById(cityName).style.display = "block";
            evt.currentTarget.className += " active";
        }
    </script>
</head>

<body>
    <div style="padding-left: 20px">
        <table>
            <tr style="white-space: nowrap; overflow: hidden;">
                <td>
                    <img src="assets/logo.png" style="height:  100px;" />
                </td>
                <td style="text-align: left; padding-left: 12px;">
                    <div style="font-size: 240%;"><b style="font-size: 120%;">Generative AI Inventory</div>
                </td>
            </tr>
        </table>

        <div style="text-align: left; margin-top: 10px; margin-bottom: 20px;">
            A curated inventory of generative AI resources
        </div>
    </div>
    <div class="tab">
        <button class="tablinks active" onclick="openTab(event, 'llms')">LLMs</button>
        <button class="tablinks" onclick="openTab(event, 'running')">LLM Hosting</button>
        <button class="tablinks" onclick="openTab(event, 'agents')">Agent Frameworks</button>
    </div>

    <div id="llms" class="tabcontent" style="display: block">
        <div style="margin-left: 14px; padding-top: 20px; padding-bottom: 20px; color: grey; text-align: left;">
            <div>
                <input id="filter" type="text" placeholder="search..."
                    style="font-size: 16px; height: 32px; width: 320px; margin-bottom: 10px" onkeyup="update()">
                <div id="search-summary" style="display: inline-block"></div>
            </div>
        </div>
        <div id="content" style="text-align: left;"></div>
    </div>

    <div id="running" class="tabcontent" style="">
        <div id="content_running" style="text-align: left;"></div>
    </div>

    <div id="agents" class="tabcontent" style="">
        <div id="content_agents" style="text-align: left;"></div>
    </div>

    <script>
        const data = {"frontier_labs": [{"name": "OpenAI", "url": "https://openai.com", "description": "", "logo": "openai.png", "country": "us", "models": [{"id": "gpt-5", "name": "GPT-5", "release_date": "2025-08-07", "modalities": ["text", "image", "audio", "video"], "context_window_tokens": null, "access": {"chatgpt_free": true, "chatgpt_plus": true, "chatgpt_pro": true, "api": true}}, {"id": "gpt-4o", "name": "GPT-4o", "release_date": "2024-05-13", "modalities": ["text", "image", "audio", "video"], "context_window_tokens": 128000, "access": {"chatgpt_free": true, "chatgpt_plus": true, "api": true}}, {"id": "gpt-4o-mini", "name": "GPT-4o Mini", "release_date": "2024-07-18", "modalities": ["text", "image"], "context_window_tokens": 128000, "access": {"chatgpt_free": false, "chatgpt_plus": true, "api": true}}, {"id": "gpt-4.1", "name": "GPT-4.1", "release_date": "2025-04-14", "modalities": ["text", "image"], "context_window_tokens": 1000000, "access": {"chatgpt_plus": true, "api": true}}, {"id": "gpt-4.1-mini", "name": "GPT-4.1 Mini", "release_date": "2025-04-14", "modalities": ["text", "image"], "context_window_tokens": null, "access": {"chatgpt_free": true, "api": true}}, {"id": "gpt-4.1-nano", "name": "GPT-4.1 Nano", "release_date": "2025-04-14", "modalities": ["text"], "context_window_tokens": null, "access": {"api": true}}, {"id": "gpt-4.5", "name": "GPT-4.5 (Preview)", "release_date": "2025-02-27", "modalities": ["text"], "context_window_tokens": 32000, "access": {"chatgpt_plus": true, "api": true, "api_note": "API deprecated July 14, 2025; still accessible in ChatGPT for some paid tiers"}}, {"id": "o1-preview", "name": "o1 Preview", "release_date": "2024-09-12", "modalities": ["text"], "context_window_tokens": 32000, "access": {"chatgpt_pro": true, "api": true}}, {"id": "o1-pro", "name": "o1 Pro", "release_date": "2025-03-19", "modalities": ["text"], "context_window_tokens": 32000, "access": {"chatgpt_pro": true, "api": true}}, {"id": "o3", "name": "o3", "release_date": "2025-04-16", "modalities": ["text"], "context_window_tokens": 32000, "access": {"chatgpt_pro": true, "api": true}}, {"id": "o3-mini", "name": "o3 Mini", "release_date": "2025-01-31", "modalities": ["text"], "context_window_tokens": 16000, "access": {"chatgpt_plus": true, "api": true}}, {"id": "o3-pro", "name": "o3 Pro", "release_date": "2025-06-10", "modalities": ["text"], "context_window_tokens": 32000, "access": {"chatgpt_pro": true, "api": true}}, {"id": "o4-mini", "name": "o4 Mini", "release_date": "2025-04-16", "modalities": ["text", "image"], "context_window_tokens": 16000, "access": {"chatgpt_free": true, "api": true}}, {"id": "sora", "name": "Sora", "release_date": "2024-02-15", "modalities": ["text-to-video"], "access": {"api": false}}, {"id": "gpt-image-1", "name": "GPT Image 1", "release_date": "2024-11-06", "modalities": ["text-to-image"], "access": {"chatgpt_plus": true, "api": true}}, {"id": "gpt-oss-120b", "name": "GPT-OSS 120B", "release_date": "2025-08-05", "modalities": ["text"], "context_window_tokens": 128000, "access": {"open_weights": true, "license": "Apache-2.0", "huggingface": true}}, {"id": "gpt-oss-20b", "name": "GPT-OSS 20B", "release_date": "2025-08-05", "modalities": ["text"], "context_window_tokens": 128000, "access": {"open_weights": true, "license": "Apache-2.0", "huggingface": true}}]}, {"name": "Anthropic", "url": "https://anthropic.com", "description": "", "logo": "anthropic.png", "country": "us", "models": [{"id": "claude-opus-4.1", "name": "Claude Opus 4.1", "release_date": "2025-08-05", "modalities": ["text", "image"], "context_window_tokens": 200000, "access": {"api": true, "google_cloud_vertex_ai": true, "amazon_bedrock": true, "claude_pro_max_team_enterprise": true}}, {"id": "claude-opus-4", "name": "Claude Opus 4", "release_date": "2025-05-22", "modalities": ["text", "image"], "context_window_tokens": 200000, "access": {"api": true, "google_cloud_vertex_ai": true, "amazon_bedrock": true, "claude_pro_max_team_enterprise": true}, "pricing": {"input_per_million_tokens": 15, "output_per_million_tokens": 75}}, {"id": "claude-sonnet-4", "name": "Claude Sonnet 4", "release_date": "2025-05-22", "modalities": ["text", "image"], "context_window_tokens": 200000, "access": {"api": true, "google_cloud_vertex_ai": true, "amazon_bedrock": true, "free_and_paid_users": true}, "pricing": {"input_per_million_tokens": 3, "output_per_million_tokens": 15}}, {"id": "claude-sonnet-3.7", "name": "Claude 3.7 Sonnet", "release_date": "2025-02-24", "modalities": ["text", "image"], "context_window_tokens": 200000, "access": {"api": true, "claude_paid_users": true}}, {"id": "claude-sonnet-3.5", "name": "Claude 3.5 Sonnet", "release_date": "2024-06-20", "modalities": ["text", "image"], "context_window_tokens": 200000, "access": {"api": true, "google_cloud_vertex_ai": true, "amazon_bedrock": true, "free_web_ios": true, "paid_subscribers": true}, "pricing": {"input_per_million_tokens": 3, "output_per_million_tokens": 15}}, {"id": "claude-3.5-haiku", "name": "Claude 3.5 Haiku", "release_date": "2024-12-12", "modalities": ["text"], "context_window_tokens": 200000, "access": {"web_mobile_all_users": true}}, {"id": "claude-2.1", "name": "Claude 2.1", "release_date": "2023-11-21", "modalities": ["text", "image"], "context_window_tokens": 200000, "access": {"legacy": true}}, {"id": "claude-instant-1.2", "name": "Claude Instant 1.2", "release_date": "2023-08-11", "modalities": ["text"], "context_window_tokens": 100000, "access": {"legacy": true, "faster_cheaper": true}}]}, {"name": "Google", "url": "https://google.com", "description": "", "logo": "google-gemini.png", "country": "us", "models": [{"id": "gemini-2.5-pro", "name": "Gemini 2.5 Pro", "release_date": "2025-03-25", "modalities": ["text", "image", "audio", "video"], "context_window_tokens": 1000000, "access": {"api": true, "google_ai_pro": true}}, {"id": "gemini-2.5-flash", "name": "Gemini 2.5 Flash", "release_date": "2025-05-20", "modalities": ["text", "image", "audio"], "context_window_tokens": 1000000, "access": {"api": true, "google_ai_studio": true}}, {"id": "gemini-2.5-flash-lite", "name": "Gemini 2.5 Flash-Lite", "release_date": "2025-06-17", "modalities": ["text", "image", "audio"], "context_window_tokens": 1000000, "access": {"api": true, "public_preview": true}}, {"id": "gemini-2.0-flash", "name": "Gemini 2.0 Flash", "release_date": "2024-12-11", "modalities": ["text", "image", "audio"], "context_window_tokens": 1000000, "access": {"api": true, "experiment": true}}, {"id": "gemini-2.0-pro-experimental", "name": "Gemini 2.0 Pro Experimental", "release_date": "2024-12-11", "modalities": ["text", "image", "audio", "video"], "context_window_tokens": 2000000, "access": {"api": false, "experimental": true}}, {"id": "gemini-1.5-pro", "name": "Gemini 1.5 Pro", "release_date": "2024-02-15", "modalities": ["text", "image", "audio"], "context_window_tokens": 1000000, "access": {"api": "legacy", "google_ai_studio": true}}, {"id": "gemini-1.5-flash", "name": "Gemini 1.5 Flash", "release_date": "2024-05-14", "modalities": ["text", "image", "audio"], "context_window_tokens": 1000000, "access": {"api": "legacy", "public": true}}, {"id": "gemini-nano", "name": "Gemini Nano", "release_date": "2023-12-06", "modalities": ["text", "image"], "context_window_tokens": 32768, "access": {"edge_sdk": true}}, {"id": "gemma-3", "name": "Gemma 3", "release_date": "2025-03-12", "modalities": ["text", "image"], "context_window_tokens": 131072, "access": {"open_source": true, "api": true}}, {"id": "gemma-3n", "name": "Gemma 3n", "release_date": "2025-03-12", "modalities": ["text", "image"], "context_window_tokens": 131072, "access": {"open_source": true, "edge_sdk": true}}]}, {"name": "Meta", "url": "https://meta.com", "description": "", "logo": "meta.png", "country": "us", "models": [{"id": "llama-3-8b", "name": "Llama 3 8B", "release_date": "2024-04-18", "parameters": "8_000_000_000", "context_window_tokens": 8192, "modalities": ["text"], "access": {"open_source": true, "huggingface": true}}, {"id": "llama-3-70b", "name": "Llama 3 70B", "release_date": "2024-04-18", "parameters": "70_600_000_000", "context_window_tokens": 8192, "modalities": ["text"], "access": {"open_source": true, "huggingface": true}}, {"id": "llama-3-1-405b", "name": "Llama 3.1 405B", "release_date": "2024-07-23", "parameters": "405_000_000_000", "context_window_tokens": 128000, "modalities": ["text"], "access": {"open_source": true, "huggingface": true, "ibm_watsonx": true}}, {"id": "llama-3-1-70b", "name": "Llama 3.1 70B", "release_date": "2024-07-23", "parameters": "70_600_000_000", "context_window_tokens": 128000, "modalities": ["text"], "access": {"open_source": true, "huggingface": true}}, {"id": "llama-3-1-8b", "name": "Llama 3.1 8B", "release_date": "2024-07-23", "parameters": "8_000_000_000", "context_window_tokens": 128000, "modalities": ["text"], "access": {"open_source": true, "huggingface": true}}, {"id": "llama-3-2-90b-vision", "name": "Llama 3.2 90B Vision", "release_date": "2024-09-25", "parameters": "90_000_000_000", "context_window_tokens": 128000, "modalities": ["text", "image"], "access": {"amazon_bedrock": true}}, {"id": "llama-3-2-11b-vision", "name": "Llama 3.2 11B Vision", "release_date": "2024-09-25", "parameters": "11_000_000_000", "context_window_tokens": 128000, "modalities": ["text", "image"], "access": {"amazon_bedrock": true}}, {"id": "llama-3-2-3b", "name": "Llama 3.2 3B", "release_date": "2024-09-25", "parameters": "3_000_000_000", "context_window_tokens": 128000, "modalities": ["text"], "access": {"amazon_bedrock": true}}, {"id": "llama-3-2-1b", "name": "Llama 3.2 1B", "release_date": "2024-09-25", "parameters": "1_000_000_000", "context_window_tokens": 128000, "modalities": ["text"], "access": {"amazon_bedrock": true}}, {"id": "llama-3-3-70b", "name": "Llama 3.3 70B", "release_date": "2024-12-01", "parameters": "70_000_000_000", "context_window_tokens": 128000, "modalities": ["text"], "access": {"open_source": true}}]}, {"name": "Microsoft", "url": "https://microsoft.com", "description": "", "logo": "microsoft.png", "country": "us", "models": [{"id": "phi-4-mini-flash-reasoning", "name": "Phi-4 Mini Flash Reasoning", "release_date": "2025-07-15", "parameters": 3800000000, "context_window_tokens": 64000, "modalities": ["text"], "access": {"azure_ai_foundry": true, "open_source": true, "huggingface": true}, "features": ["hybrid SambaY architecture", "low latency (2\u20133\u00d7 faster)"]}, {"id": "orca-2-7b", "name": "Orca 2 7B", "release_date": "2023-11", "parameters": 7000000000, "context_window_tokens": 32000, "modalities": ["text"], "access": {"open_source": true, "huggingface": true}, "features": ["small-model reasoning via synthetic data"]}, {"id": "orca-2-13b", "name": "Orca 2 13B", "release_date": "2023-11", "parameters": 13000000000, "context_window_tokens": 32000, "modalities": ["text"], "access": {"open_source": true, "huggingface": true}, "features": ["small-model reasoning via synthetic data"]}, {"id": "megatron-turing-nlg-530b", "name": "Megatron-Turing NLG 530B", "release_date": "2021-10-11", "parameters": 530000000000, "context_window_tokens": 2048, "modalities": ["text"], "access": {"proprietary": true, "azure": true}, "features": ["large general English text generation"]}, {"id": "copilot (gpt-4o based)", "name": "Microsoft Copilot", "release_date": "2023-02-07", "based_on": "GPT-4 series", "modalities": ["text", "image"], "access": {"windows": true, "microsoft_365": true, "edge": true, "bing": true}, "features": ["conversational assistant", "IDE/code support"]}]}, {"name": "Alibaba Cloud", "url": "https://alibabacloud.com", "description": "", "logo": "alibaba.png", "country": "cn", "models": [{"id": "qwen-max", "name": "Qwen-Max", "release_date": "2025-07-16", "modalities": ["text"], "context_window_tokens": 32768, "access": {"api": true, "model_studio": true}, "pricing_per_million_input": 1.6, "pricing_per_million_output": 6.4}, {"id": "qwen-plus", "name": "Qwen-Plus", "release_date": "2025-07-16", "modalities": ["text"], "context_window_tokens": 131072, "access": {"api": true, "model_studio": true}, "pricing_per_million_input": 0.4, "pricing_per_million_output": 1.2}, {"id": "qwen-turbo", "name": "Qwen-Turbo", "release_date": "2025-07-16", "modalities": ["text"], "context_window_tokens": 1008192, "access": {"api": true, "model_studio": true}, "pricing_per_million_input": 0.05, "pricing_per_million_output": 0.2}, {"id": "qwen-omni-7b", "name": "Qwen2.5-Omni-7B", "release_date": "2025-03-26", "modalities": ["text", "image", "audio", "video"], "context_window_tokens": 32768, "access": {"open_source": true, "huggingface": true}}, {"id": "qwen2.5-vl-32b-instruct", "name": "Qwen2.5-VL-32B-Instruct", "release_date": "2025-03-24", "modalities": ["text", "image"], "context_window_tokens": 32768, "access": {"open_source": true, "huggingface": true}}, {"id": "qwq-32b", "name": "QwQ-32B-Preview", "release_date": "2024-11", "modalities": ["text"], "context_window_tokens": 32000, "access": {"open_source": true, "huggingface": true}}, {"id": "qwen3-235b", "name": "Qwen3-235B", "release_date": "2025-04-28", "parameters": 235000000000, "modalities": ["text"], "context_window_tokens": 128000, "access": {"open_source": true, "huggingface": true}}, {"id": "qwen3-30b", "name": "Qwen3-30B-MoE", "release_date": "2025-04-28", "parameters": 30000000000, "activated_parameters": 3000000000, "modalities": ["text"], "context_window_tokens": 128000, "access": {"open_source": true, "huggingface": true}}]}, {"name": "DeepSeek", "url": "https://deepseek.com", "description": "", "logo": "deepseek.png", "country": "cn", "models": [{"id": "deepseek-v3", "name": "DeepSeek V3", "release_date": "2024-12-26", "parameters": 671000000000, "modalities": ["text"], "context_window_tokens": 128000, "access": {"open_source": true, "api": true}}, {"id": "deepseek-reasoner-r1", "name": "DeepSeek R1 (Reasoner)", "release_date": "2025-01-21", "based_on": "DeepSeek V3", "modalities": ["text"], "context_window_tokens": 64000, "access": {"open_source": true, "api": true}}, {"id": "deepseek-reasoner-r1-zero", "name": "DeepSeek R1-Zero", "release_date": "2025-01-21", "based_on": "DeepSeek V3", "modalities": ["text"], "context_window_tokens": 64000, "access": {"open_source": true, "api": true}}]}, {"name": "Amazon", "url": "https://amazon.com", "description": "", "logo": "amazon.png", "country": "us", "models": [{"id": "amazon.titan-text-premier-v1:0", "name": "Amazon Titan Text Premier", "release_date": "2024-05-07", "modalities": ["text"], "context_window_tokens": 32000, "access": {"aws_bedrock": true}}, {"id": "amazon.titan-text-express-v1", "name": "Amazon Titan Text Express", "release_date": "2024-05-07", "modalities": ["text"], "context_window_tokens": 8000, "access": {"aws_bedrock": true}}, {"id": "amazon.titan-text-lite-v1", "name": "Amazon Titan Text Lite", "release_date": "2024-05-07", "modalities": ["text"], "context_window_tokens": 4000, "access": {"aws_bedrock": true}}, {"id": "amazon.titan-text-embeddings-v2", "name": "Amazon Titan Text Embeddings V2", "release_date": "2024-04-30", "modalities": ["text-embeddings"], "context_window_tokens": 8000, "access": {"aws_bedrock": true}}, {"id": "amazon.titan-multimodal-embeddings-g1", "name": "Amazon Titan Multimodal Embeddings G1", "release_date": "2024-05-07", "modalities": ["text", "image", "embeddings"], "access": {"aws_bedrock": true}}, {"id": "amazon.titan-image-generator-g1-v1", "name": "Amazon Titan Image Generator G1", "release_date": "2023-11-29", "modalities": ["image-generation"], "access": {"aws_bedrock": true}}, {"id": "amazon.nova-micro", "name": "Amazon Nova Micro", "release_date": "2024-12-03", "modalities": ["text"], "access": {"aws_bedrock": true}}, {"id": "amazon.nova-lite", "name": "Amazon Nova Lite", "release_date": "2024-12-03", "modalities": ["text", "image", "video"], "access": {"aws_bedrock": true}}, {"id": "amazon.nova-pro", "name": "Amazon Nova Pro", "release_date": "2024-12-03", "modalities": ["text", "image", "video"], "access": {"aws_bedrock": true}}, {"id": "amazon.nova-canvas", "name": "Amazon Nova Canvas", "release_date": "2024-12-03", "modalities": ["image-generation"], "access": {"aws_bedrock": true}}, {"id": "amazon.nova-reel", "name": "Amazon Nova Reel", "release_date": "2024-12-03", "modalities": ["video-generation"], "access": {"aws_bedrock": true}}, {"id": "amazon.q", "name": "Amazon Q (Assistant)", "release_date": "2023-11-28", "modalities": ["text", "code", "data"], "access": {"aws_q": true}}]}, {"name": "Apple", "url": "https://apple.com", "description": "", "logo": "apple.png", "country": "us", "models": [{"id": "openelm", "name": "OpenELM", "release_date": "2024-04-22", "parameters": 1000000000, "modalities": ["text"], "context_window_tokens": 4096, "access": {"open_source": true, "huggingface": true, "on_device": true}}, {"id": "apple-foundation-on-device-3b", "name": "Apple Foundation On-Device 3B", "release_date": "2025-06-10", "parameters": 3000000000, "modalities": ["text"], "context_window_tokens": 8192, "access": {"on_device": true, "foundation_models_api": true}}, {"id": "apple-foundation-cloud", "name": "Apple Foundation Cloud Model", "release_date": "2025-06-10", "modalities": ["text"], "access": {"private_cloud_compute": true, "on_server": true}}, {"id": "diffucoder-7b-cpgrpo", "name": "DiffuCoder 7B cpGRPO", "release_date": "2025-07-04", "parameters": 7000000000, "modalities": ["text", "code"], "context_window_tokens": 8192, "access": {"open_source": true, "huggingface": true}}, {"id": "mm1", "name": "MM1", "release_date": "2025-03-14", "modalities": ["text", "image"], "context_window_tokens": 8192, "access": {"research_preview": true, "multimodal": true}}]}, {"name": "Mistral", "url": "https://mistral.ai", "description": "", "logo": "mistral.png", "country": "eu", "models": [{"id": "mistral-medium-2505", "name": "Mistral Medium 3", "release_date": "2025-05-07", "modalities": ["text"], "context_window_tokens": 128000, "access": {"api": true, "commercial_license": true}, "pricing_per_million_input": 0.4, "pricing_per_million_output": 2.0}, {"id": "magistral-medium-2506", "name": "Magistral Medium", "release_date": "2025-06-10", "modalities": ["text"], "context_window_tokens": 40000, "access": {"api": true, "commercial_license": true}, "features": ["reasoning model"]}, {"id": "codestral-2501", "name": "Codestral 2", "release_date": "2025-01-25", "modalities": ["text", "code"], "context_window_tokens": 256000, "access": {"api": true, "commercial_license": true}, "features": ["coding specialized"]}, {"id": "voxtral-mini-2507", "name": "Voxtral Mini", "release_date": "2025-07-25", "modalities": ["audio"], "context_window_tokens": 32000, "access": {"api": true, "open_source": true}, "features": ["transcription"]}, {"id": "devstral-medium-2507", "name": "Devstral Medium", "release_date": "2025-07-25", "modalities": ["text", "code"], "context_window_tokens": 128000, "access": {"api": true, "commercial_license": true}, "features": ["software-engineering agent"]}, {"id": "mistral-ocr-2505", "name": "Mistral OCR 2", "release_date": "2025-05-25", "modalities": ["image", "text"], "context_window_tokens": 128000, "access": {"api": true, "commercial_license": true}, "features": ["OCR"]}, {"id": "ministral-3b-2410", "name": "Ministral 3B", "release_date": "2024-10-01", "parameters": 3000000000, "modalities": ["text"], "context_window_tokens": 128000, "access": {"api": true, "research_license": true}}, {"id": "ministral-8b-2410", "name": "Ministral 8B", "release_date": "2024-10-01", "parameters": 8000000000, "modalities": ["text"], "context_window_tokens": 128000, "access": {"research_license": true}}, {"id": "mistral-large-2411", "name": "Mistral Large 2", "release_date": "2024-11-19", "parameters": 123000000000, "modalities": ["text"], "context_window_tokens": 128000, "access": {"research_license": true}}, {"id": "pixtral-large-2411", "name": "Pixtral Large", "release_date": "2024-11-19", "parameters": 124000000000, "modalities": ["text", "image"], "context_window_tokens": 128000, "access": {"research_license": true}}, {"id": "mistral-small-2506", "name": "Mistral Small 3.2", "release_date": "2025-06-01", "parameters": 24000000000, "modalities": ["text"], "context_window_tokens": 128000, "access": {"open_source": true}}, {"id": "magistral-small-2506", "name": "Magistral Small", "release_date": "2025-06-10", "parameters": 24000000000, "modalities": ["text"], "context_window_tokens": 40000, "access": {"open_source": true}, "features": ["reasoning"]}, {"id": "devstral-small-2507", "name": "Devstral Small 1.1", "release_date": "2025-07-25", "parameters": 24000000000, "modalities": ["text", "code"], "context_window_tokens": 128000, "access": {"open_source": true}}, {"id": "mistral-small-2503", "name": "Mistral Small 3.1", "release_date": "2025-03-17", "parameters": 24000000000, "modalities": ["text", "image"], "context_window_tokens": 128000, "access": {"open_source": true}}]}, {"name": "XAI", "url": "https://xai.com", "description": "", "logo": "xai.png", "country": "us", "models": [{"id": "grok-1", "name": "Grok 1", "release_date": "2023-11-03", "modalities": ["text"], "context_window_tokens": 8000, "access": {"open_source": true, "x_premium": true}}, {"id": "grok-1.5", "name": "Grok 1.5", "release_date": "2024-03-29", "modalities": ["text"], "context_window_tokens": 128000, "access": {"x_premium": true}}, {"id": "grok-2", "name": "Grok 2", "release_date": "2024-08-20", "modalities": ["text", "image"], "context_window_tokens": 128000, "access": {"x_premium": true}}, {"id": "grok-2-mini", "name": "Grok 2 Mini", "release_date": "2024-08-20", "modalities": ["text", "image"], "context_window_tokens": 128000, "access": {"x_premium": true}}, {"id": "grok-3", "name": "Grok 3", "release_date": "2025-02-17", "modalities": ["text", "image"], "context_window_tokens": 128000, "access": {"supergrok_subscribers": true, "api": true, "x_premium": true}}, {"id": "grok-3-mini", "name": "Grok 3 Mini", "release_date": "2025-02-17", "modalities": ["text", "image"], "context_window_tokens": 128000, "access": {"supergrok_subscribers": true, "x_premium": true}}, {"id": "grok-4", "name": "Grok 4", "release_date": "2025-07-09", "modalities": ["text", "image", "search", "tool-use", "voice"], "context_window_tokens": null, "access": {"supergrok_heavy": true, "x_premium": true}}, {"id": "grok-4-heavy", "name": "Grok 4 Heavy", "release_date": "2025-07-09", "modalities": ["text", "image", "search", "tool-use", "voice"], "context_window_tokens": null, "access": {"supergrok_heavy": true}}, {"id": "baby-grok", "name": "Baby Grok", "release_date": "2025-07-21", "modalities": ["text"], "context_window_tokens": 64000, "access": {"x_premium": false, "kids_mode": true}}]}, {"name": "Cohere", "url": "https://cohere.com", "description": "Enterprise-focused LLMs and retrieval/reranking.", "logo": "cohere.png", "country": "ca", "models": [{"id": "command-r-plus", "name": "Command R+", "release_date": "2024-03", "modalities": ["text"], "context_window_tokens": 128000, "access": {"api": true, "vertex_ai": true, "aws_bedrock": true}}, {"id": "command-r", "name": "Command R", "release_date": "2024-03", "modalities": ["text"], "context_window_tokens": 128000, "access": {"api": true, "vertex_ai": true, "aws_bedrock": true}}, {"id": "aya-23", "name": "Aya 23 (open)", "release_date": "2024-02-13", "modalities": ["text"], "context_window_tokens": 32768, "access": {"open_source": true, "huggingface": true}}]}, {"name": "Databricks", "url": "https://databricks.com", "description": "Open-weights enterprise LLMs.", "logo": "databricks.png", "country": "us", "models": [{"id": "dbrx-base", "name": "DBRX Base", "release_date": "2024-03-27", "modalities": ["text"], "context_window_tokens": 32768, "access": {"open_source": true, "huggingface": true, "api": true}}, {"id": "dbrx-instruct", "name": "DBRX Instruct", "release_date": "2024-03-27", "modalities": ["text"], "context_window_tokens": 32768, "access": {"open_source": true, "huggingface": true, "api": true}}]}, {"name": "NVIDIA", "url": "https://www.nvidia.com", "description": "Open models and reasoning family for agents.", "logo": "nvidia.png", "country": "us", "models": [{"id": "nemotron-4-340b-base", "name": "Nemotron-4 340B Base", "release_date": "2024-06-14", "parameters": 340000000000, "modalities": ["text"], "context_window_tokens": null, "access": {"open_source": true, "huggingface": true}}, {"id": "nemotron-4-340b-instruct", "name": "Nemotron-4 340B Instruct", "release_date": "2024-06-14", "parameters": 340000000000, "modalities": ["text"], "context_window_tokens": null, "access": {"open_source": true, "huggingface": true}}, {"id": "llama-3.3-nemotron-super-49b-v1.5", "name": "Llama-3.3-Nemotron-Super-49B v1.5", "release_date": "2025-07-27", "parameters": 49000000000, "modalities": ["text"], "context_window_tokens": null, "access": {"nvidia_build": true}}]}, {"name": "Baidu", "url": "https://yiyan.baidu.com", "description": "ERNIE model family (YiYan/Ernie Bot).", "logo": "baidu.png", "country": "cn", "models": [{"id": "ernie-4.0", "name": "ERNIE 4.0", "release_date": "2023-10-17", "modalities": ["text", "image"], "context_window_tokens": null, "access": {"api": true}}, {"id": "ernie-4.5", "name": "ERNIE 4.5 (family)", "release_date": "2025-07-01", "modalities": ["text", "image"], "context_window_tokens": null, "access": {"open_source": true, "huggingface": true, "api": true}}]}, {"name": "01.AI", "url": "https://01.ai", "description": "Yi open-weights family.", "logo": "01ai.png", "country": "cn", "models": [{"id": "yi-34b", "name": "Yi-34B", "release_date": "2023-11-23", "parameters": 34000000000, "modalities": ["text"], "context_window_tokens": 200000, "access": {"open_source": true, "huggingface": true}}, {"id": "yi-1.5-34b", "name": "Yi-1.5-34B", "release_date": "2024-06-26", "parameters": 34000000000, "modalities": ["text"], "context_window_tokens": 200000, "access": {"open_source": true, "huggingface": true}}, {"id": "yi-vl-34b", "name": "Yi-VL-34B", "release_date": "2024-01-23", "parameters": 34000000000, "modalities": ["text", "image"], "context_window_tokens": 200000, "access": {"open_source": true, "huggingface": true}}]}, {"name": "Moonshot AI", "url": "https://www.moonshot.ai", "description": "Kimi chatbot & open models.", "logo": "moonshot.png", "country": "cn", "models": [{"id": "kimi-k1.5", "name": "Kimi k1.5", "release_date": "2025-01-20", "modalities": ["text", "code"], "context_window_tokens": 128000, "access": {"api": true}}, {"id": "kimi-k2", "name": "Kimi K2 (open weights)", "release_date": "2025-07-11", "parameters": 1000000000000, "modalities": ["text", "code"], "context_window_tokens": null, "access": {"open_source": true, "huggingface": true}}]}]}.frontier_labs;
        const running = {"updated_at": "2025-08-19", "categories": [{"category": "managed_api_llm", "description": "Fully managed, vendor-hosted LLMs exposed as simple APIs. You send prompts; the provider handles hosting, scaling, safety features, and updates. Fastest path to production with minimal infrastructure control."}, {"category": "cloud_model_platform", "description": "Hyperscaler platforms that host multiple foundation models (first-party and third-party) with managed endpoints inside your cloud account. Provide governance, tuning, evals, monitoring, and integrations with other cloud services."}, {"category": "inference_cloud", "description": "Specialized providers focused on high-performance model serving (often open-weight or custom) via serverless or dedicated endpoints. Emphasize low latency, high throughput, easy scaling, and cost efficiency without full cloud lock-in."}, {"category": "gpu_cloud_infrastructure", "description": "Raw GPU compute (IaaS) or serverless GPU pods you control to run your own inference stack. Maximum flexibility and performance tuning, but you manage runtimes, scaling, security hardening, and reliability."}, {"category": "model_router_gateway", "description": "Abstraction layers that route a single API across many models/providers. Add features like fallback, load balancing, caching, observability, guardrails, and policy\u2014sometimes available as SaaS or self-hosted gateways."}, {"category": "on_prem_platform", "description": "Turnkey software/hardware stacks to run LLMs in private data centers (including air-gapped). Provide orchestration, security, model catalogs, and enterprise controls; often built around Kubernetes and NVIDIA/NPU accelerators."}, {"category": "open_source_inference_engine", "description": "Self-hostable runtimes/servers (OSS) for deploying LLMs anywhere (cloud, on-prem). Common features include continuous batching, paged KV caches, tensor optimizations, and quantization support. You operate the stack."}, {"category": "local_runtime_app", "description": "Desktop apps/CLIs that download and run models on a laptop or workstation (often quantized). Provide simple UIs and lightweight HTTP APIs for local development and privacy-preserving use."}, {"category": "edge_on_device", "description": "SDKs/runtimes to run compact or optimized models directly on phones, PCs with NPUs, or embedded/edge devices. Prioritize privacy, offline use, and real-time latency; requires model conversion and hardware-specific optimizations."}], "options": [{"name": "OpenAI API", "provider": "OpenAI", "category": "managed_api_llm", "deployment_modes": ["SaaS/API"], "notes": "GPT-5 series, o3/o4 reasoning, image/audio, embeddings, tools/agents.", "sources": ["S1", "S11", "S12"]}, {"name": "Claude API", "provider": "Anthropic", "category": "managed_api_llm", "deployment_modes": ["SaaS/API"], "notes": "Claude 4 family; long-context options.", "sources": ["S2", "S3", "S19"]}, {"name": "Gemini API", "provider": "Google", "category": "managed_api_llm", "deployment_modes": ["SaaS/API"], "notes": "Gemini family via Google AI for Developers.", "sources": ["S5", "S18"]}, {"name": "Azure OpenAI Service", "provider": "Microsoft", "category": "managed_api_llm", "deployment_modes": ["SaaS/API (Azure)"], "notes": "OpenAI models on Azure with enterprise controls.", "sources": ["S6", "S9", "S13"]}, {"name": "Cohere API", "provider": "Cohere", "category": "managed_api_llm", "deployment_modes": ["SaaS/API"], "notes": "Command family, embeddings, rerank.", "sources": ["S7"]}, {"name": "Mistral La Plateforme (API)", "provider": "Mistral AI", "category": "managed_api_llm", "deployment_modes": ["SaaS/API"], "notes": "Mistral/Mixtral models, function calling, streaming.", "sources": ["S8"]}, {"name": "AI21 Studio / AI21 API", "provider": "AI21 Labs", "category": "managed_api_llm", "deployment_modes": ["SaaS/API"], "notes": "Jamba/J2 models, text & embeddings.", "sources": ["S9a"]}, {"name": "Aleph Alpha API", "provider": "Aleph Alpha", "category": "managed_api_llm", "deployment_modes": ["SaaS/API", "EU hosting"], "notes": "Luminous/Alpha family with multimodal & explainability.", "sources": ["S10"]}, {"name": "Grok API", "provider": "xAI", "category": "managed_api_llm", "deployment_modes": ["SaaS/API"], "notes": "Grok-4 with OpenAI-compatible API.", "sources": ["S16", "S1xai", "S2xai", "S3xai"]}, {"name": "Amazon Bedrock", "provider": "AWS", "category": "cloud_model_platform", "deployment_modes": ["AWS managed endpoints"], "notes": "Multi-provider foundation model hub with regional availability.", "sources": ["S12", "S13", "S14b", "S14c", "S14d"]}, {"name": "Amazon SageMaker JumpStart", "provider": "AWS", "category": "cloud_model_platform", "deployment_modes": ["Managed endpoints (SageMaker)"], "notes": "Deploy 400+ open-weights FMs incl. DeepSeek, Llama, Mistral.", "sources": ["S65", "S65b", "S65c"]}, {"name": "Vertex AI (Generative AI)", "provider": "Google Cloud", "category": "cloud_model_platform", "deployment_modes": ["GCP managed endpoints"], "notes": "Gemini & partner models with lifecycle/versions.", "sources": ["S4", "S6g"]}, {"name": "Azure AI Foundry \u2014 Model Catalog", "provider": "Microsoft Azure", "category": "cloud_model_platform", "deployment_modes": ["Azure managed endpoints"], "notes": "Catalog includes Microsoft, OpenAI, DeepSeek, Mistral, xAI, Cohere, Meta.", "sources": ["S13", "S9", "S12a"]}, {"name": "IBM watsonx.ai", "provider": "IBM", "category": "cloud_model_platform", "deployment_modes": ["IBM Cloud", "Software (self-managed)"], "notes": "Granite + third-party/open models; Model Gateway.", "sources": ["S36", "S37", "S22news", "S22a"]}, {"name": "Snowflake Cortex", "provider": "Snowflake", "category": "cloud_model_platform", "deployment_modes": ["Managed in-account"], "notes": "Built-in LLM functions and model access inside Snowflake.", "sources": ["S59"]}, {"name": "Databricks Mosaic AI Model Serving", "provider": "Databricks", "category": "cloud_model_platform", "deployment_modes": ["Managed endpoints / serverless"], "notes": "Serve OSS & custom models; tools for RAG/agents.", "sources": ["S60"]}, {"name": "Oracle OCI Generative AI", "provider": "Oracle Cloud", "category": "cloud_model_platform", "deployment_modes": ["OCI managed endpoints"], "notes": "Managed generative AI (models & tuning).", "sources": ["S61"]}, {"name": "Hugging Face Inference Endpoints", "provider": "Hugging Face", "category": "cloud_model_platform", "deployment_modes": ["Managed per-model endpoints"], "notes": "Hosted endpoints with autoscaling & TGI/vLLM engines.", "sources": ["S16"]}, {"name": "Together AI", "provider": "Together", "category": "inference_cloud", "deployment_modes": ["SaaS/API", "serverless"], "notes": "High-throughput OSS model inference & fine-tuning.", "sources": ["S17"]}, {"name": "Fireworks AI", "provider": "Fireworks", "category": "inference_cloud", "deployment_modes": ["SaaS/API", "serverless"], "notes": "Fast inference for OSS models, tool use, agents.", "sources": ["S18"]}, {"name": "Replicate", "provider": "Replicate", "category": "inference_cloud", "deployment_modes": ["SaaS/API"], "notes": "Run models as APIs; deploy your own containers.", "sources": ["S19"]}, {"name": "OctoAI", "provider": "OctoAI", "category": "inference_cloud", "deployment_modes": ["SaaS/API"], "notes": "Endpoints for OSS/custom models; LangChain integrations.", "sources": ["S20"]}, {"name": "Baseten", "provider": "Baseten", "category": "inference_cloud", "deployment_modes": ["SaaS/API", "VPC/VNet options"], "notes": "Production LLM inference; dedicated deployments.", "sources": ["S21", "S21b"]}, {"name": "Modal", "provider": "Modal Labs", "category": "inference_cloud", "deployment_modes": ["Serverless GPUs"], "notes": "Bring-your-code serverless GPU compute for inference.", "sources": ["S22", "S22b"]}, {"name": "GroqCloud", "provider": "Groq", "category": "inference_cloud", "deployment_modes": ["Groq LPU cloud"], "notes": "Ultra-low-latency inference for supported open models.", "sources": ["S14", "S15"]}, {"name": "OpenRouter", "provider": "OpenRouter", "category": "model_router_gateway", "deployment_modes": ["SaaS/API"], "notes": "Meta-API routing across 100s of models/providers.", "sources": ["S23", "S63"]}, {"name": "Portkey", "provider": "Portkey", "category": "model_router_gateway", "deployment_modes": ["Gateway (SaaS/self-host)"], "notes": "Model catalog, routing, guardrails, observability.", "sources": ["S24"]}, {"name": "Helicone Gateway", "provider": "Helicone", "category": "model_router_gateway", "deployment_modes": ["Gateway (open-source/SaaS)"], "notes": "Routing, caching, telemetry for LLM APIs.", "sources": ["S25"]}, {"name": "CoreWeave", "provider": "CoreWeave", "category": "gpu_cloud_infrastructure", "deployment_modes": ["GPU cloud IaaS"], "notes": "GPU VMs & inference stacks for self-hosting.", "sources": ["S26"]}, {"name": "Lambda Cloud", "provider": "Lambda Labs", "category": "gpu_cloud_infrastructure", "deployment_modes": ["GPU cloud IaaS"], "notes": "On-demand GPUs & clusters for training/inference.", "sources": ["S27"]}, {"name": "Crusoe Cloud", "provider": "Crusoe", "category": "gpu_cloud_infrastructure", "deployment_modes": ["GPU cloud IaaS"], "notes": "Sustainable GPU cloud for AI workloads.", "sources": ["S30"]}, {"name": "RunPod", "provider": "RunPod", "category": "gpu_cloud_infrastructure", "deployment_modes": ["GPU serverless/Pods"], "notes": "Pods & serverless GPUs; templates for TGI/vLLM/SGLang.", "sources": ["S28", "S20r"]}, {"name": "Vast.ai", "provider": "Vast.ai", "category": "gpu_cloud_infrastructure", "deployment_modes": ["GPU marketplace"], "notes": "Spot rental GPUs; TGI serverless templates.", "sources": ["S29", "S21v"]}, {"name": "VMware Private AI Foundation with NVIDIA", "provider": "VMware/Broadcom + NVIDIA", "category": "on_prem_platform", "deployment_modes": ["Private datacenter", "Air-gapped"], "notes": "NVIDIA NIM microservices, Model Store, secure on-prem AI.", "sources": ["S32", "S33", "S32pdf"]}, {"name": "Red Hat OpenShift AI", "provider": "Red Hat", "category": "on_prem_platform", "deployment_modes": ["Kubernetes (hybrid/on-prem)"], "notes": "Lifecycle mgmt & serving for predictive/gen-AI at scale.", "sources": ["S34", "S35", "S38r"]}, {"name": "HPE Private Cloud AI", "provider": "HPE + NVIDIA", "category": "on_prem_platform", "deployment_modes": ["Private cloud (on-prem)"], "notes": "Turnkey AI factory systems with NVIDIA GPUs.", "sources": ["S17h", "S17h2", "S17h3"]}, {"name": "Dell AI Factory / Platforms", "provider": "Dell Technologies", "category": "on_prem_platform", "deployment_modes": ["On-prem/private cloud"], "notes": "Validated designs & turnkey \u2018AI factory\u2019 systems.", "sources": ["S17d", "S17d2", "S17d3", "S17d4"]}, {"name": "NVIDIA NIM", "provider": "NVIDIA", "category": "on_prem_platform", "deployment_modes": ["Containers (on-prem/cloud/edge)"], "notes": "Inference microservices for LLMs (NGC, Triton, TensorRT-LLM).", "sources": ["S31"]}, {"name": "NVIDIA Triton Inference Server", "provider": "NVIDIA", "category": "open_source_inference_engine", "deployment_modes": ["On-prem/cloud/edge"], "notes": "Multi-framework inference server; LLM backends incl. TensorRT-LLM.", "sources": ["S38", "S41n"]}, {"name": "NVIDIA TensorRT-LLM", "provider": "NVIDIA", "category": "open_source_inference_engine", "deployment_modes": ["On-prem/cloud"], "notes": "High-performance LLM runtime & kernels; Triton backend.", "sources": ["S39", "S41n2", "S41n3"]}, {"name": "KServe", "provider": "CNCF", "category": "open_source_inference_engine", "deployment_modes": ["Kubernetes"], "notes": "CRDs for serving predictive & generative models; LLM features.", "sources": ["S40", "S40g"]}, {"name": "Seldon Core", "provider": "Seldon", "category": "open_source_inference_engine", "deployment_modes": ["Kubernetes"], "notes": "K8s-native model serving & monitoring.", "sources": ["S41"]}, {"name": "Ray Serve (LLM APIs)", "provider": "Anyscale/Ray", "category": "open_source_inference_engine", "deployment_modes": ["On-prem/cloud"], "notes": "Distributed LLM serving with OpenAI-compatible APIs.", "sources": ["S42", "S42f"]}, {"name": "BentoML (LLM serving)", "provider": "BentoML", "category": "open_source_inference_engine", "deployment_modes": ["On-prem/cloud"], "notes": "Packaging & scaling LLM services; speculative decoding optimizations.", "sources": ["S43", "S43b"]}, {"name": "vLLM", "provider": "vLLM Project", "category": "open_source_inference_engine", "deployment_modes": ["On-prem/cloud"], "notes": "High-throughput LLM server with paged KV cache.", "sources": ["S44", "S44g"]}, {"name": "Text Generation Inference (TGI)", "provider": "Hugging Face", "category": "open_source_inference_engine", "deployment_modes": ["On-prem/cloud"], "notes": "Production LLM server (Rust/Python), continuous batching, LoRA, AMD ROCm support.", "sources": ["S45", "S45g", "S45r"]}, {"name": "SGLang", "provider": "SGLang Project", "category": "open_source_inference_engine", "deployment_modes": ["On-prem/cloud"], "notes": "Fast serving engine for LLM/VLM; EP & KV-reuse features.", "sources": ["S46s", "S46s2", "S46s3"]}, {"name": "LMDeploy (TurboMind/PyTorch engines)", "provider": "OpenMMLab/InternLM", "category": "open_source_inference_engine", "deployment_modes": ["On-prem/cloud"], "notes": "Inference/serving toolkit; supports popular OSS models.", "sources": ["S46", "S46d", "S46i"]}, {"name": "llama.cpp", "provider": "Community (ggerganov)", "category": "open_source_inference_engine", "deployment_modes": ["Local/edge/on-prem"], "notes": "CPU/GPU-portable LLM inference in C/C++; quantization support.", "sources": ["S47"]}, {"name": "Ollama", "provider": "Ollama", "category": "local_runtime_app", "deployment_modes": ["Laptop/desktop/server"], "notes": "One-line local model runner & registry; simple HTTP API.", "sources": ["S48"]}, {"name": "LM Studio", "provider": "LM Studio", "category": "local_runtime_app", "deployment_modes": ["Laptop/desktop"], "notes": "GUI to run/chat with local models; uses local backends.", "sources": ["S49"]}, {"name": "GPT4All (Desktop)", "provider": "Nomic", "category": "local_runtime_app", "deployment_modes": ["Laptop/desktop"], "notes": "Fully local chatbot app; optional local API server.", "sources": ["S50", "S50b", "S50c"]}, {"name": "Koboldcpp", "provider": "KoboldCPP", "category": "local_runtime_app", "deployment_modes": ["Laptop/desktop"], "notes": "Lightweight UI/server for local LLMs; roleplay/story use cases.", "sources": ["S52"]}, {"name": "MLC LLM", "provider": "MLC/TVM", "category": "local_runtime_app", "deployment_modes": ["Laptop/desktop/web"], "notes": "WebGPU & native runtimes for local OSS models.", "sources": ["S51"]}, {"name": "Apple MLX / mlx-lm", "provider": "Apple MLX team", "category": "local_runtime_app", "deployment_modes": ["Mac (Apple Silicon)"], "notes": "Apple-optimized local LLM library on MLX.", "sources": ["S53"]}, {"name": "Intel OpenVINO GenAI", "provider": "Intel", "category": "open_source_inference_engine", "deployment_modes": ["On-prem/edge/laptop"], "notes": "Optimized CPU/iGPU inference for LLMs with quantization.", "sources": ["S54"]}, {"name": "ONNX Runtime GenAI", "provider": "Microsoft", "category": "edge_on_device", "deployment_modes": ["On-device/edge/cloud"], "notes": "Run SLMs/LLMs on CPU/GPU/NPU; Windows ML & DirectML support.", "sources": ["S57", "S58", "S57p"]}, {"name": "NVIDIA Jetson (Generative AI/NIM on Jetson)", "provider": "NVIDIA", "category": "edge_on_device", "deployment_modes": ["Edge devices"], "notes": "Embedded LLM/VLM deployment on Jetson platforms.", "sources": ["S55"]}, {"name": "Qualcomm AI Hub (on-device)", "provider": "Qualcomm", "category": "edge_on_device", "deployment_modes": ["Mobile/PC (NPU)"], "notes": "On-device LLM workflows for Snapdragon platforms.", "sources": ["S56"]}, {"name": "Argonne ALCF Inference Endpoints", "provider": "ALCF", "category": "inference_cloud", "deployment_modes": ["Hosted endpoints (research)"], "notes": "API access to OSS models on HPC hardware.", "sources": ["S62"]}]};
        const agents = {"updated_at": "2025-09-06", "categories": [{"category": "agent_platform_managed", "description": "Managed/SaaS agent platforms with hosted state, tool execution, files, retrieval, and governance."}, {"category": "workflow_lowcode", "description": "No/low-code canvases and automation platforms for composing agents and tools as flows."}, {"category": "agent_framework", "description": "Code-first libraries for building tool-using, stateful agents (routing, memory, planning, tool calling)."}, {"category": "multi_agent_framework", "description": "Libraries focused on coordinating multiple agents (roles, teams, negotiation, supervisor patterns)."}, {"category": "eval_observability", "description": "Evals, tracing, debugging, A/B testing, and analytics for agent systems in prod."}, {"category": "guardrails_safety", "description": "Safety, validation, and policy enforcement layers to constrain agent behavior."}, {"category": "domain_agent_product", "description": "Verticalized, end-user agent products (e.g., developer IDE agents, design assistants, productivity copilots) delivered as SaaS/desktop apps rather than build frameworks."}], "options": [{"name": "Responses API", "provider": "OpenAI", "category": "agent_platform_managed", "deployment_modes": ["SaaS/API"], "notes": "Successor to Assistants API (2025). Unified API for agents with streaming, built-in tools (web search, file search, computer use), and SDK integration."}, {"name": "OpenAI Assistants API", "provider": "OpenAI", "category": "agent_platform_managed", "deployment_modes": ["SaaS/API"], "notes": "Hosted threads, tools/function calling, file search/vector stores, workflows & tool execution. Being phased out in favor of Responses API."}, {"name": "Anthropic Messages (Tool Use & Computer Use)", "provider": "Anthropic", "category": "agent_platform_managed", "deployment_modes": ["SaaS/API"], "notes": "Structured tool use, input/output text+image, and managed \u2018computer use\u2019 for software control."}, {"name": "Google Vertex AI Agent Builder", "provider": "Google Cloud", "category": "agent_platform_managed", "deployment_modes": ["GCP"], "notes": "Dialogflow CX + search grounding + tools; integrates with Gemini and enterprise data."}, {"name": "Azure AI Agent Service", "provider": "Microsoft Azure", "category": "agent_platform_managed", "deployment_modes": ["Azure"], "notes": "Agentic orchestration with state, tools, connectors, and Azure governance."}, {"name": "OpenRouter Actions", "provider": "OpenRouter", "category": "agent_platform_managed", "deployment_modes": ["SaaS/API"], "notes": "Model routing + tool/action execution as a hosted layer for agents."}, {"name": "Continue (IDE Agent)", "provider": "Continue", "category": "agent_platform_managed", "deployment_modes": ["VS Code/JetBrains"], "notes": "Local-first IDE agent; model-agnostic; supports tools and context streaming."}, {"name": "OpenAI Codex Agent", "provider": "OpenAI", "category": "domain_agent_product", "deployment_modes": ["SaaS/API", "CLI", "IDE plugins"], "notes": "Expanded developer agent (2025) integrated with GitHub, terminals, IDEs. Provides coding assistance, debugging, PR suggestions, and context retention."}, {"name": "GitHub Copilot", "provider": "GitHub (Microsoft)", "category": "domain_agent_product", "deployment_modes": ["SaaS", "IDE extensions (VS Code/JetBrains)", "CLI"], "notes": "Developer-focused agent for code completion, refactoring, and chat. Integrated with GitHub repos, issues, and pull requests."}, {"name": "Cursor", "provider": "Cursor", "category": "domain_agent_product", "deployment_modes": ["Desktop app", "SaaS backend"], "notes": "Agentic IDE with coding, refactoring, debugging, and multi-agent personas. Treats the development environment as an interactive workspace."}, {"name": "Figma AI", "provider": "Figma", "category": "domain_agent_product", "deployment_modes": ["SaaS/Web app"], "notes": "Design assistant integrated into Figma. Offers natural-language design generation, layout adjustments, asset search, and collaboration tools."}, {"name": "Notion AI", "provider": "Notion", "category": "domain_agent_product", "deployment_modes": ["SaaS/Web app/Desktop app"], "notes": "Productivity copilot embedded in Notion. Handles summarization, drafting, Q&A over workspace content, and project management assistance."}, {"name": "LangChain", "provider": "LangChain", "category": "agent_framework", "deployment_modes": ["Library (Python/JS)"], "notes": "Tool calling, routing, memory, callbacks. Pairs with LangGraph for durable, stateful agents."}, {"name": "LangGraph", "provider": "LangChain", "category": "agent_framework", "deployment_modes": ["Library (Python/JS)"], "notes": "Graph-based, interruptible, resumable agent runtime; human-in-the-loop; multi-agent patterns."}, {"name": "LlamaIndex", "provider": "LlamaIndex", "category": "agent_framework", "deployment_modes": ["Library (Python/JS)"], "notes": "RAG-first agents, tools, routers, observability; integrates with many vector stores."}, {"name": "Semantic Kernel", "provider": "Microsoft", "category": "agent_framework", "deployment_modes": ["Library (.NET/Python/JS)"], "notes": "Pluggable planners, connectors, memory, and orchestration for agent skills."}, {"name": "DSPy", "provider": "Stanford", "category": "agent_framework", "deployment_modes": ["Library (Python)"], "notes": "Declarative LLM programming; optimizes prompts/routing for chains & agents."}, {"name": "Haystack Agents", "provider": "deepset", "category": "agent_framework", "deployment_modes": ["Library (Python)"], "notes": "Pipelines + agents with strong RAG and tool integration."}, {"name": "Aider", "provider": "aider.chat", "category": "agent_framework", "deployment_modes": ["CLI"], "notes": "Codebase-aware coding agent using Git diffs; resilient refactoring workflows."}, {"name": "OpenAI Agents SDK", "provider": "OpenAI", "category": "agent_framework", "deployment_modes": ["Library (Python/TypeScript)"], "notes": "Lightweight primitives for building single- and multi-agent systems (agents, handoffs, sessions, tracing, guardrails). Provider-agnostic; integrates with Temporal and supports MCP."}, {"name": "Model Context Protocol (MCP)", "provider": "Anthropic (adopted widely)", "category": "agent_framework", "deployment_modes": ["Library/SDK (Python, TypeScript, C#, Java)"], "notes": "Open interoperability standard (2024). Enables tool/data integrations across frameworks. Adopted in OpenAI Agents SDK, Responses API, Microsoft Copilot Studio, and more."}, {"name": "AutoGen", "provider": "Microsoft Research", "category": "multi_agent_framework", "deployment_modes": ["Library (Python)"], "notes": "Conversational multi-agent orchestration with tool/LLM/human agents and group chats."}, {"name": "crewAI", "provider": "crewAI", "category": "multi_agent_framework", "deployment_modes": ["Library (Python/JS)"], "notes": "Role-based multi-agent teams, tasks, tools, and process supervision."}, {"name": "FlowiseAI", "provider": "Flowise", "category": "workflow_lowcode", "deployment_modes": ["Self-host/SaaS"], "notes": "Drag-and-drop canvas for LangChain/LlamaIndex style agents; REST APIs & auth."}, {"name": "n8n (AI + Agents)", "provider": "n8n", "category": "workflow_lowcode", "deployment_modes": ["Self-host/SaaS"], "notes": "Automation workflows with LLM nodes, tools, and webhooks to operationalize agents."}, {"name": "Zapier AI Actions", "provider": "Zapier", "category": "workflow_lowcode", "deployment_modes": ["SaaS"], "notes": "Natural-language actions that let agents operate 6000+ SaaS apps securely."}, {"name": "Langfuse", "provider": "Langfuse", "category": "eval_observability", "deployment_modes": ["Self-host/SaaS"], "notes": "Tracing, datasets, evals, A/B tests, and prompt/version management for agents."}, {"name": "Weights & Biases (Weave/Evals)", "provider": "W&B", "category": "eval_observability", "deployment_modes": ["SaaS"], "notes": "Experiment tracking plus eval pipelines and dashboards for agent performance."}, {"name": "OpenAI Evals", "provider": "OpenAI", "category": "eval_observability", "deployment_modes": ["SaaS/API"], "notes": "Regression tests and dataset-driven evals to guard agent quality over time."}, {"name": "AgentScope", "provider": "Research (2025)", "category": "eval_observability", "deployment_modes": ["Library (Python)"], "notes": "Developer-centric framework with unified interfaces, async execution, sandboxing, and eval tooling."}, {"name": "Agent Lightning", "provider": "Research (2025)", "category": "eval_observability", "deployment_modes": ["Library (Python)"], "notes": "RL training framework decoupled from execution. Supports integration with LangChain, OpenAI Agents SDK, AutoGen."}, {"name": "Cerebrum (AIOS SDK)", "provider": "Research (2025)", "category": "agent_framework", "deployment_modes": ["SDK / Workflow Platform"], "notes": "Provides agent SDK, hub, and testing/eval features. Supports deployment, discovery, and distribution."}, {"name": "Guardrails AI", "provider": "Guardrails AI", "category": "guardrails_safety", "deployment_modes": ["Library/SaaS"], "notes": "Schema validation, semantic checks, moderation & policy enforcement for agents."}, {"name": "NeMo Guardrails", "provider": "NVIDIA", "category": "guardrails_safety", "deployment_modes": ["Library (Python)"], "notes": "Rail-spec safety & grounded flows; complements NVIDIA NIM and RAG stacks."}, {"name": "Rebuff", "provider": "Rebuff", "category": "guardrails_safety", "deployment_modes": ["Library"], "notes": "Prompt injection/jailbreak defenses, detectors, and sanitization for tool-using agents."}]};

        function getDisplayText(str, filters) {
            if (str && str.length > 0) {
                for (let i in filters.filter(f => f && f.length > 0)) {
                    const filter = filters[i];
                    const lowerStr = str.toLowerCase();
                    const lowerFilter = filter.toLowerCase();
                    const idx = lowerStr.indexOf(lowerFilter);

                    if (idx !== -1) {
                        // Capitalize first letter of str
                        let displayStr = str.charAt(0).toUpperCase() + str.slice(1);
                        // Find the index in the capitalized string
                        let capOffset = 0;
                        if (idx === 0) {
                            capOffset = 0;
                        } else {
                            capOffset = idx;
                        }
                        // Insert <span> around the matched filter
                        return (
                            displayStr.slice(0, capOffset) +
                            '<span style="background: #ffe066;">' +
                            displayStr.slice(capOffset, capOffset + filter.length) +
                            '</span>' +
                            displayStr.slice(capOffset + filter.length)
                        );
                    }
                }
                return str.slice(0, 1).toUpperCase() + str.slice(1);
            }
            return str;
        }

        function matchesAnyFilter(str, filters) {
            for (let i in filters.filter(f => f && f.length > 0)) {
                if (str.toLowerCase().includes(filters[i].toLowerCase())) {
                    return true;
                }
            }
            return false;
        }

        function search(filters) {
            const textToSearch = function (item) {
                const models = item.models.map(m => m.name + ' ' + m.release_date + ' ' + m.modalities.join(' '));
                return (item.name + ' ' + models).toLowerCase();
            }
            return data.filter(i => i.name).filter(item => filters.length === 0 || matchesAnyFilter(textToSearch(item), filters));
        }

        function getFilters(filterText) {
            return filterText.split(';').map(f => f.trim()).filter(f => f && f.length > 0);
        }

        function update() {
            const filterText = document.getElementById('filter').value.toLowerCase().trim()
            const filters = getFilters(filterText);
            let html = '';

            let filteredData = search(filters);
            document.getElementById('search-summary').innerHTML = ' = ' + filteredData.length + ' ' + (filteredData.length === 1 ? 'item' : 'items');

            filteredData.forEach(item => {
                html += '<div class="group" style="text-align: center;">';
                html += '<div class="advice-as-title" title="' + item.name + '">';
                const openModels = renderModels(item, true, 'darkgreen');
                html += '<div style="font-size: 12px; color: darkgreen;">open-weight models (' + openModels.count + ')</div>';
                html += openModels.html;
                html += '</div>';

                html += '<a target="_blank" href="https://google.com/search?q=' + item.name + ' LLMs">';
                html += '<div>';
                html += `<img src="assets/${item.logo}" style="height: 100px; width: 140px; object-fit: contain;" />`;
                html += '</div>';
                html += '<div style="text-align: right; margin-top: -60px; padding-right: 10px; margin-bottom: 42px;">';
                html += `<img src="https://zeljkoobrenovic.github.io/sokrates-media/flags/1x1/${item.country}.svg" style="height: 24px; border-radius: 50%;" />`;
                html += '</div>';

                html += '<div class="advice-as-title" title="' + item.name + '" style="color: darkred">';
                html += '</a>';

                const closedModels = renderModels(item, false, 'black');
                html += '<div style="font-size: 12px; color: black;">proprietary models (' + closedModels.count + ')</div>';
                html += closedModels.html;
                html += '</div>';


                function renderModels(item, open_source, color) {
                    if (!item.models) return { count: 0, html: '' };
                    let models = item.models.filter(m => (!open_source && (!m.access || !m.access.open_source)) || (open_source && m.access && m.access.open_source) || (open_source && m.access && m.access.open_weights));

                    if (models.length === 0) return { count: 0, html: '' };

                    let html = '<div style="font-size: 11px;">';
                    // Sort models by release_date (null/undefined at the end)
                    let sortedModels = models.sort((a, b) => {
                        if (!a.release_date && !b.release_date) return 0;
                        if (!a.release_date) return -1;
                        if (!b.release_date) return 1;
                        return b.release_date.localeCompare(a.release_date);
                    });
                    sortedModels.forEach(model => {
                        let opacity = (model.release_date.includes('2025') || model.release_date.includes('2024')) ? 1 : 0.4;
                        let modalities = model.modalities ? model.modalities.join(' + ') : '';
                        let model_display_text = getDisplayText(model.name, filters);
                        html += '<a target="_blank" href="https://google.com/search?q=' + item.name + ' ' + model.name + ' LLM">';
                        html += `<div style="color: ${color}; font-size: 12px; white-space: nowrap; overflow: hidden; text-overflow: ellipsis; text-align: left; background: white; border: 1px solid lightgrey; display: block; margin: 2px; padding: 2px 4px; border-radius: 4px; opacity: ${opacity}; font-weight: bold;">
                            ${model_display_text}
                            <div style="font-size: 10px; color: grey;">${model.release_date} | ${modalities}</div></div>`;
                        html += '</a>';
                    });
                    html += '</div>';
                    return { count: models.length, html: html };
                }
                html += '</div>';
                html += '</div>';
            });

            document.getElementById('content').innerHTML = html;
        }

        function updateRunning(groups, list, name) {
            let html = '';

            html += '<div style="padding: 20px">';
            html += '<table>';
            html += '<tr style="font-size: 80%; text-align: center">';
            groups.forEach(group => {
                html += '<td style="border-bottom: 3px solid grey" colspan="' + group.size + '">' + group.name + '</td>';
            });
            html += '</tr>';
            html += '<tr style="font-size: 60%; text-align: center">';
            list.categories.forEach(category => {
                html += '<td style="width: 140px; min-width: 140px; max-width: 140px">';
                const displayName = category.category.replace(/_/g, ' ');
                html += '<a target="_blank" href="https://google.com/search?q=LLM ' + displayName + '">'
                html += '<img style="height: 70px; margin: 4px;" src="assets/' + category.category + '.png" title="' + category.description + '">';
                html += '</a>';
                html += '</td>';
            });
            html += '</tr>';
            html += '<tr style="font-size: 60%; text-align: center; color: blue">';
            list.categories.forEach(category => {
                html += '<td style="width: 140px; min-width: 140px; max-width: 140px">';
                const displayName = category.category.replace(/_/g, ' ');
                html += '<a target="_blank" href="https://google.com/search?q=describe:LLM ' + displayName + '">'
                html += '<div title="' + category.description + '">' + displayName + '</div>';
                html += '</a>';
                html += '</td>';
            });
            html += '</tr>';
            html += '<tr>';
            list.categories.forEach(category => {
                html += '<td style="vertical-align: top">';
                list.options.filter(o => o.category === category.category).forEach(option => {
                    html += '<a target="_blank" href="https://google.com/search?q=' + option.provider + ' ' + option.name + '">'
                    html += '<div style="padding: 4px; margin: 8px; box-shadow: rgba(99, 99, 99, 0.2) 0px 2px 8px 0px;">';
                    html += '<div style="font-size: 70%; color: grey">' + option.provider + '</div>';
                    html += '<div style="font-size: 80%">' + option.name + '</div>';
                    html += '</a>';
                    html += '</div>';
                });
                html += '</td>';
            });
            html += '</tr>';
            html += '</table>';
            html += '</div>';

            document.getElementById('content_' + name).innerHTML = html;
        }

        update();
        updateRunning([{ size: 1, name: 'proprietary' }, { size: 4, name: 'public cloud and services' }, { size: 4, name: 'on-prem / device /SDKs' }], running, 'running');
        updateRunning([{ size: 2, name: 'managed platforms' }, { size: 2, name: 'frameworks & sdks' }, { size: 2, name: 'safety & guardrails' }, { size: 1, name: 'verticalized products' }], agents, 'agents');
    </script>
</body>

</html>